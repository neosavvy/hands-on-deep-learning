{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neosavvy/hands-on-deep-learning/blob/master/HODL_Lecture_2_Heart_Disease_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZuGNXc58pgl"
      },
      "source": [
        "# Binary Classification on Tabular Data - Predicting Heart Disease\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTigfjFI8pgn"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This colab shows to set up and train a Neural Network model for *binary classification*, when the dataset is *tabular* (rather than unstructured data like images or text) and has a mix of numeric and categorical features. Since tabular datasets are often made available in CSV files, the colab demonstrates the full CSV-to-trained-model workflow.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### The dataset\n",
        "\n",
        "The dataset ([more background on the data](https://archive.ics.uci.edu/ml/datasets/heart+Disease)) has information on 303 patients, one in each row. Each column (i.e., feature) contains information on a particular attribute of the patient. The column named \"Target\" indicates if the patient has been diagnosed with heart disease or not and is the label (i.e., the dependent variable) that we want to predict using the other columns. \n",
        "\n",
        "Feature description (copied from [here](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)):\n",
        "\n",
        "Column| Description| Feature Type\n",
        "------------|--------------------|----------------------\n",
        "Age | Age in years | Numerical\n",
        "Sex | (1 = male; 0 = female) | Categorical\n",
        "CP | Chest pain type (0, 1, 2, 3, 4) | Categorical\n",
        "Trestbpd | Resting blood pressure (in mm Hg on admission) | Numerical\n",
        "Chol | Serum cholesterol in mg/dl | Numerical\n",
        "FBS | fasting blood sugar in 120 mg/dl (1 = true; 0 = false) | Categorical\n",
        "RestECG | Resting electrocardiogram results (0, 1, 2) | Categorical\n",
        "Thalach | Maximum heart rate achieved | Numerical\n",
        "Exang | Exercise induced angina (1 = yes; 0 = no) | Categorical\n",
        "Oldpeak | ST depression induced by exercise relative to rest | Numerical\n",
        "Slope | Slope of the peak exercise ST segment | Numerical\n",
        "CA | Number of major vessels (0-3) colored by fluoroscopy | Both numerical & categorical\n",
        "Thal | 3 = normal; 6 = fixed defect; 7 = reversible defect | Categorical\n",
        "Target | Diagnosis of heart disease (1 = true; 0 = false) | Target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7YELlPx8pgo"
      },
      "source": [
        "## Technical preliminaries\n",
        "\n",
        "Throughout the course, we will load the following packages as the first step and set the seed for different random number generators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqhnaoXC8pgp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# initialize the seeds of different random number generators so that the \n",
        "# results will be the same every time the notebook is run\n",
        "keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRS8tSL-8pgp"
      },
      "source": [
        "## Read in the data\n",
        "\n",
        "Conveniently, the dataset in CSV form has been made available online (by [Francois Chollet](https://twitter.com/fchollet)) and we can load it into a Pandas dataframe with the very useful `pd.read_csv` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwIi1uXT8pgq"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0gs3ULo8pgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "295f9078-86e9-448f-98f5-c4b2423789bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWQPAk_R8pgq"
      },
      "source": [
        "The dataset has 303 rows and 14 columns (13 independent variables + 1 dependent variable):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV1UP8MN8pgr"
      },
      "source": [
        "Let's take a look at the first few rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z8LPV1n8pgr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2147f6f5-7cf6-4171-e138-315a3419352d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
              "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
              "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
              "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
              "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
              "\n",
              "   ca        thal  target  \n",
              "0   0       fixed       0  \n",
              "1   3      normal       1  \n",
              "2   2  reversible       0  \n",
              "3   0      normal       0  \n",
              "4   0      normal       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80fc3c10-650d-4ba9-9395-ad8a2f864a0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>fixed</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>160</td>\n",
              "      <td>286</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>reversible</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80fc3c10-650d-4ba9-9395-ad8a2f864a0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80fc3c10-650d-4ba9-9395-ad8a2f864a0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80fc3c10-650d-4ba9-9395-ad8a2f864a0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp9o9bm58pgu"
      },
      "source": [
        "## Preprocessing \n",
        "\n",
        "This dataset has both categorical variables and numeric variables.\n",
        "\n",
        "We'd like to preprocess them as follows:\n",
        "- *one-hot encode* the categorical variables\n",
        "- *normalize* the numeric variables\n",
        "\n",
        "It will be convenient (for later processing) to collect these groups of variables into two lists."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_variables = ['sex', 'cp', 'fbs', 'restecg','exang', 'ca', 'thal']\n",
        "numerics = ['age', 'trestbps','chol', 'thalach', 'oldpeak', 'slope']"
      ],
      "metadata": {
        "id": "sY6ASs0BTlUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "With the pandas `get_dummies` function, you can one-hot-encode in one line.\n"
      ],
      "metadata": {
        "id": "_y45-rf-ZdOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns = categorical_variables)"
      ],
      "metadata": {
        "id": "8rOCggp2Tius"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "iEeCwpvQfilR",
        "outputId": "ce4482b6-3a90-4a4b-94b3-9edd80c2ac74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  trestbps  chol  thalach  oldpeak  slope  target  sex_0  sex_1  cp_0  \\\n",
              "0   63       145   233      150      2.3      3       0      0      1     0   \n",
              "1   67       160   286      108      1.5      2       1      0      1     0   \n",
              "2   67       120   229      129      2.6      2       0      0      1     0   \n",
              "3   37       130   250      187      3.5      3       0      0      1     0   \n",
              "4   41       130   204      172      1.4      1       0      1      0     0   \n",
              "\n",
              "   ...  exang_1  ca_0  ca_1  ca_2  ca_3  thal_1  thal_2  thal_fixed  \\\n",
              "0  ...        0     1     0     0     0       0       0           1   \n",
              "1  ...        1     0     0     0     1       0       0           0   \n",
              "2  ...        1     0     0     1     0       0       0           0   \n",
              "3  ...        0     1     0     0     0       0       0           0   \n",
              "4  ...        0     1     0     0     0       0       0           0   \n",
              "\n",
              "   thal_normal  thal_reversible  \n",
              "0            0                0  \n",
              "1            1                0  \n",
              "2            0                1  \n",
              "3            1                0  \n",
              "4            1                0  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c69c6395-472c-4236-9f2e-8181ac69666a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>target</th>\n",
              "      <th>sex_0</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_0</th>\n",
              "      <th>...</th>\n",
              "      <th>exang_1</th>\n",
              "      <th>ca_0</th>\n",
              "      <th>ca_1</th>\n",
              "      <th>ca_2</th>\n",
              "      <th>ca_3</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_fixed</th>\n",
              "      <th>thal_normal</th>\n",
              "      <th>thal_reversible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>150</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67</td>\n",
              "      <td>160</td>\n",
              "      <td>286</td>\n",
              "      <td>108</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67</td>\n",
              "      <td>120</td>\n",
              "      <td>229</td>\n",
              "      <td>129</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>187</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>172</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c69c6395-472c-4236-9f2e-8181ac69666a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c69c6395-472c-4236-9f2e-8181ac69666a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c69c6395-472c-4236-9f2e-8181ac69666a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK3j-Baa8pgs"
      },
      "source": [
        "\n",
        "Before we normalize the numerics, let's split the data into an 80% training set and 20% test set (*why should we split **before** normalization?*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1aHFYse8pgs"
      },
      "outputs": [],
      "source": [
        "test_df = df.sample(frac=0.2, random_state=42)\n",
        "train_df = df.drop(test_df.index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiTJwFySfphD",
        "outputId": "c1ed61a2-285e-4a3b-9211-b6b9ac9fb85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(242, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpxTky1ONepp",
        "outputId": "cc6c44ff-2fd9-49a4-c791-c1d29de39224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, let's calculate the mean and standard deviation of every numeric variable in the training set."
      ],
      "metadata": {
        "id": "UwrTlwA3NhuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "means = train_df[numerics].mean()\n",
        "sd = train_df[numerics].std()"
      ],
      "metadata": {
        "id": "thKdv04AZfhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "means"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMUE8D9Jfuv7",
        "outputId": "10260618-2f81-49b7-ecdf-33da5dc6fea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age          54.268595\n",
              "trestbps    131.995868\n",
              "chol        246.512397\n",
              "thalach     149.805785\n",
              "oldpeak       1.032645\n",
              "slope         1.590909\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's normalize the train and test dataframes with these means and standard deviations."
      ],
      "metadata": {
        "id": "L1YP45i4Zfzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[numerics]= (train_df[numerics] - means)/sd"
      ],
      "metadata": {
        "id": "LPtsJD6jZ5E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[numerics]= (test_df[numerics] - means)/sd"
      ],
      "metadata": {
        "id": "hqzdrYJbaHT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "y5jErgL5fycw",
        "outputId": "fdf8be7d-0cc7-45fa-8ace-ce70ab0b63fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  trestbps      chol   thalach   oldpeak     slope  target  sex_0  \\\n",
              "0  0.963746  0.721939 -0.278690  0.008396  1.083461  2.226814       0      0   \n",
              "1  1.405254  1.554681  0.814423 -1.807247  0.399542  0.646494       1      0   \n",
              "2  1.405254 -0.665964 -0.361189 -0.899426  1.339930  0.646494       0      0   \n",
              "3 -1.906055 -0.110803  0.071931  1.607891  2.109339  2.226814       0      0   \n",
              "4 -1.464547 -0.110803 -0.876809  0.959447  0.314052 -0.933825       0      1   \n",
              "\n",
              "   sex_1  cp_0  ...  exang_1  ca_0  ca_1  ca_2  ca_3  thal_1  thal_2  \\\n",
              "0      1     0  ...        0     1     0     0     0       0       0   \n",
              "1      1     0  ...        1     0     0     0     1       0       0   \n",
              "2      1     0  ...        1     0     0     1     0       0       0   \n",
              "3      1     0  ...        0     1     0     0     0       0       0   \n",
              "4      0     0  ...        0     1     0     0     0       0       0   \n",
              "\n",
              "   thal_fixed  thal_normal  thal_reversible  \n",
              "0           1            0                0  \n",
              "1           0            1                0  \n",
              "2           0            0                1  \n",
              "3           0            1                0  \n",
              "4           0            1                0  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cf6e4bd-2c87-403c-b117-cb53efb38e78\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>target</th>\n",
              "      <th>sex_0</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_0</th>\n",
              "      <th>...</th>\n",
              "      <th>exang_1</th>\n",
              "      <th>ca_0</th>\n",
              "      <th>ca_1</th>\n",
              "      <th>ca_2</th>\n",
              "      <th>ca_3</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_fixed</th>\n",
              "      <th>thal_normal</th>\n",
              "      <th>thal_reversible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.963746</td>\n",
              "      <td>0.721939</td>\n",
              "      <td>-0.278690</td>\n",
              "      <td>0.008396</td>\n",
              "      <td>1.083461</td>\n",
              "      <td>2.226814</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.405254</td>\n",
              "      <td>1.554681</td>\n",
              "      <td>0.814423</td>\n",
              "      <td>-1.807247</td>\n",
              "      <td>0.399542</td>\n",
              "      <td>0.646494</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.405254</td>\n",
              "      <td>-0.665964</td>\n",
              "      <td>-0.361189</td>\n",
              "      <td>-0.899426</td>\n",
              "      <td>1.339930</td>\n",
              "      <td>0.646494</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.906055</td>\n",
              "      <td>-0.110803</td>\n",
              "      <td>0.071931</td>\n",
              "      <td>1.607891</td>\n",
              "      <td>2.109339</td>\n",
              "      <td>2.226814</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.464547</td>\n",
              "      <td>-0.110803</td>\n",
              "      <td>-0.876809</td>\n",
              "      <td>0.959447</td>\n",
              "      <td>0.314052</td>\n",
              "      <td>-0.933825</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cf6e4bd-2c87-403c-b117-cb53efb38e78')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9cf6e4bd-2c87-403c-b117-cb53efb38e78 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9cf6e4bd-2c87-403c-b117-cb53efb38e78');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The easiest way to feed data to Keras/Tensorflow is as Numpy arrays so we convert our two dataframes."
      ],
      "metadata": {
        "id": "jxB_UeNMN6Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_df.to_numpy()\n",
        "test = test_df.to_numpy()"
      ],
      "metadata": {
        "id": "0ivSr2kzW6tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, our features $X$ and dependent variable $y$ are both inside the arrays so let's separate them out.\n",
        "\n",
        "**There's a bug in the code below. See if you can spot it.**"
      ],
      "metadata": {
        "id": "ugk7qXIXON5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train[:,: -1]\n",
        "train_y = train[:, -1]\n",
        "test_X = test[:,: -1]\n",
        "test_y = test[:, -1]"
      ],
      "metadata": {
        "id": "ieb-7302dqmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select the right target column (the bug-free version)"
      ],
      "metadata": {
        "id": "95fL1gxgqRE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = 6\n",
        "features = list(range(train.shape[1]))\n",
        "features.remove(target)\n",
        "\n",
        "train_X = train[:, features]\n",
        "train_y = train[:, target]\n",
        "test_X = test[:, features]\n",
        "test_y = test[:, target]"
      ],
      "metadata": {
        "id": "FtkKhfYkqKlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape, train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcHmVPMIaS-E",
        "outputId": "36ccaf56-d9e9-4e68-b83d-a59863b2e53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((242, 29), (242,))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_X.shape, test_y.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uYWRkHIa3mL",
        "outputId": "15220e64-b3b1-4db1-8754-3d6b360e75cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((61, 29), (61,))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0wrFZ9o8pgv"
      },
      "source": [
        "## Build a model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Define model in Keras\n",
        "\n",
        "Creating an NN  is usually just a few lines of Keras code. \n",
        "\n",
        "* We will start with a single hidden layer. \n",
        "* Since this is a *binary classification problem*, we will use a sigmoid activation in the output layer."
      ],
      "metadata": {
        "id": "Gh4MNTIjreyL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69p4o0lR8pgv"
      },
      "outputs": [],
      "source": [
        "num_columns = train_X.shape[1]\n",
        "\n",
        "# define the input layer\n",
        "input = keras.Input(shape=num_columns)\n",
        "\n",
        "# feed the input vector to the hidden layer\n",
        "h = keras.layers.Dense(16, activation=\"relu\", name=\"Hidden\")(input)\n",
        "\n",
        "# feed the output of the hidden layer to the output layer\n",
        "output = keras.layers.Dense(1, activation=\"sigmoid\", name=\"Output\")(h)\n",
        "\n",
        "# tell Keras that this (input,output) pair is your model\n",
        "model = keras.Model(input, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `model.summary()` command is a good way to get a quick overview of what you have defined."
      ],
      "metadata": {
        "id": "coJALvJfPZPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUL_yaaIbGVN",
        "outputId": "978570e7-7656-4589-b2c9-126edff38a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 29)]              0         \n",
            "                                                                 \n",
            " Hidden (Dense)              (None, 16)                480       \n",
            "                                                                 \n",
            " Output (Dense)              (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 497\n",
            "Trainable params: 497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can \"visualize\" the network graphically as well using Keras' `plot_model` function."
      ],
      "metadata": {
        "id": "lfsdY6h5QBbV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHfYbbKD8pgv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "1d7bca1d-ff6c-49e9-ac87-98a8a983a3cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's hand-calculate the number of parameters to verify."
      ],
      "metadata": {
        "id": "3Rtoj4OuPzVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(29 * 16 + 16) + (16 * 1 + 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_FpjV_1PiRP",
        "outputId": "92a92889-5fba-4c9f-866e-92ee7a08aea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "497"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set optimization parameters"
      ],
      "metadata": {
        "id": "Igf5bWCZQG8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the model is defined, we need to tell Keras three things:\n",
        "\n",
        "*   What **loss function** to use - Since our output variable is binary, we will select the `binary_crossentropy` loss function. \n",
        "*   Which **optimizer** to use - we will use a sibling of SGD called **Adam** which is an excellent default choice \n",
        "*   What **metrics** you want Keras to report out - in classification problems like this one, Accuracy is usually the metric you want to see."
      ],
      "metadata": {
        "id": "vaNfhfuAQIkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "RiJgZpm2PxDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "To kickoff training, we have to decide on three things:\n",
        "* The *batch size* - 32 is a good default\n",
        "* The number of *epochs* i.e., how many passes through the training data. Usually 20-30 epochs is a good starting point but since this dataset is very small, each epoch will be very quick so let's run it for 300 epochs. It will allow us to see if any overfitting happens\n",
        "* Whether we want to use a validation set. This will be useful for overfitting detection and regularization via early stopping so we will ask Keras to automatically use 20% of the data points as a validation set"
      ],
      "metadata": {
        "id": "8_gDdeqiQUeN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPZFylPP8pgw"
      },
      "source": [
        "OK, let's train the model using the `model.fit` function!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo71UEBf8pgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824fcf12-c95e-4381-927a-a06b247e6cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "7/7 [==============================] - 6s 159ms/step - loss: 0.9632 - accuracy: 0.2280 - val_loss: 0.8962 - val_accuracy: 0.2245\n",
            "Epoch 2/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.8992 - accuracy: 0.2487 - val_loss: 0.8512 - val_accuracy: 0.3265\n",
            "Epoch 3/300\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.8433 - accuracy: 0.3005 - val_loss: 0.8113 - val_accuracy: 0.2857\n",
            "Epoch 4/300\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.7928 - accuracy: 0.3575 - val_loss: 0.7769 - val_accuracy: 0.3878\n",
            "Epoch 5/300\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.7499 - accuracy: 0.4301 - val_loss: 0.7508 - val_accuracy: 0.4490\n",
            "Epoch 6/300\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.7180 - accuracy: 0.4715 - val_loss: 0.7291 - val_accuracy: 0.4694\n",
            "Epoch 7/300\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6899 - accuracy: 0.5337 - val_loss: 0.7105 - val_accuracy: 0.5510\n",
            "Epoch 8/300\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6642 - accuracy: 0.5751 - val_loss: 0.6934 - val_accuracy: 0.5510\n",
            "Epoch 9/300\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6420 - accuracy: 0.6218 - val_loss: 0.6765 - val_accuracy: 0.6327\n",
            "Epoch 10/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6181 - accuracy: 0.6684 - val_loss: 0.6597 - val_accuracy: 0.6327\n",
            "Epoch 11/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.5938 - accuracy: 0.6995 - val_loss: 0.6446 - val_accuracy: 0.6327\n",
            "Epoch 12/300\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5724 - accuracy: 0.7409 - val_loss: 0.6317 - val_accuracy: 0.6327\n",
            "Epoch 13/300\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5525 - accuracy: 0.7565 - val_loss: 0.6196 - val_accuracy: 0.5918\n",
            "Epoch 14/300\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5334 - accuracy: 0.7513 - val_loss: 0.6091 - val_accuracy: 0.6122\n",
            "Epoch 15/300\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5149 - accuracy: 0.7565 - val_loss: 0.5997 - val_accuracy: 0.6531\n",
            "Epoch 16/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.4977 - accuracy: 0.7668 - val_loss: 0.5917 - val_accuracy: 0.6735\n",
            "Epoch 17/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.7720 - val_loss: 0.5843 - val_accuracy: 0.6939\n",
            "Epoch 18/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7720 - val_loss: 0.5784 - val_accuracy: 0.7143\n",
            "Epoch 19/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7668 - val_loss: 0.5723 - val_accuracy: 0.6939\n",
            "Epoch 20/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.7824 - val_loss: 0.5691 - val_accuracy: 0.7347\n",
            "Epoch 21/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.7927 - val_loss: 0.5651 - val_accuracy: 0.7347\n",
            "Epoch 22/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.7927 - val_loss: 0.5610 - val_accuracy: 0.7347\n",
            "Epoch 23/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.7979 - val_loss: 0.5573 - val_accuracy: 0.7347\n",
            "Epoch 24/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.7979 - val_loss: 0.5533 - val_accuracy: 0.7143\n",
            "Epoch 25/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.4013 - accuracy: 0.8031 - val_loss: 0.5493 - val_accuracy: 0.7143\n",
            "Epoch 26/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.7979 - val_loss: 0.5440 - val_accuracy: 0.6939\n",
            "Epoch 27/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.8083 - val_loss: 0.5394 - val_accuracy: 0.6939\n",
            "Epoch 28/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8187 - val_loss: 0.5343 - val_accuracy: 0.6939\n",
            "Epoch 29/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8342 - val_loss: 0.5306 - val_accuracy: 0.7143\n",
            "Epoch 30/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8342 - val_loss: 0.5267 - val_accuracy: 0.7143\n",
            "Epoch 31/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8549 - val_loss: 0.5207 - val_accuracy: 0.7143\n",
            "Epoch 32/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3596 - accuracy: 0.8653 - val_loss: 0.5150 - val_accuracy: 0.7143\n",
            "Epoch 33/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3551 - accuracy: 0.8705 - val_loss: 0.5107 - val_accuracy: 0.7347\n",
            "Epoch 34/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3512 - accuracy: 0.8705 - val_loss: 0.5074 - val_accuracy: 0.7143\n",
            "Epoch 35/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3470 - accuracy: 0.8653 - val_loss: 0.5049 - val_accuracy: 0.7143\n",
            "Epoch 36/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3429 - accuracy: 0.8705 - val_loss: 0.5034 - val_accuracy: 0.7347\n",
            "Epoch 37/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.3394 - accuracy: 0.8756 - val_loss: 0.5017 - val_accuracy: 0.7347\n",
            "Epoch 38/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3368 - accuracy: 0.8705 - val_loss: 0.5001 - val_accuracy: 0.7347\n",
            "Epoch 39/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.3338 - accuracy: 0.8705 - val_loss: 0.4986 - val_accuracy: 0.7347\n",
            "Epoch 40/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3308 - accuracy: 0.8705 - val_loss: 0.4968 - val_accuracy: 0.7551\n",
            "Epoch 41/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8756 - val_loss: 0.4955 - val_accuracy: 0.7551\n",
            "Epoch 42/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3247 - accuracy: 0.8860 - val_loss: 0.4956 - val_accuracy: 0.7143\n",
            "Epoch 43/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3217 - accuracy: 0.8912 - val_loss: 0.4960 - val_accuracy: 0.7143\n",
            "Epoch 44/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3193 - accuracy: 0.8860 - val_loss: 0.4960 - val_accuracy: 0.7143\n",
            "Epoch 45/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3170 - accuracy: 0.8808 - val_loss: 0.4949 - val_accuracy: 0.7347\n",
            "Epoch 46/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3147 - accuracy: 0.8860 - val_loss: 0.4934 - val_accuracy: 0.7551\n",
            "Epoch 47/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3125 - accuracy: 0.8808 - val_loss: 0.4925 - val_accuracy: 0.7755\n",
            "Epoch 48/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3119 - accuracy: 0.8756 - val_loss: 0.4915 - val_accuracy: 0.7755\n",
            "Epoch 49/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.3101 - accuracy: 0.8756 - val_loss: 0.4904 - val_accuracy: 0.7755\n",
            "Epoch 50/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3081 - accuracy: 0.8756 - val_loss: 0.4888 - val_accuracy: 0.7755\n",
            "Epoch 51/300\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.8808 - val_loss: 0.4876 - val_accuracy: 0.7755\n",
            "Epoch 52/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3043 - accuracy: 0.8756 - val_loss: 0.4867 - val_accuracy: 0.7755\n",
            "Epoch 53/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3026 - accuracy: 0.8808 - val_loss: 0.4857 - val_accuracy: 0.7755\n",
            "Epoch 54/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3007 - accuracy: 0.8808 - val_loss: 0.4848 - val_accuracy: 0.7755\n",
            "Epoch 55/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2990 - accuracy: 0.8808 - val_loss: 0.4840 - val_accuracy: 0.7755\n",
            "Epoch 56/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2975 - accuracy: 0.8808 - val_loss: 0.4832 - val_accuracy: 0.7755\n",
            "Epoch 57/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2959 - accuracy: 0.8860 - val_loss: 0.4823 - val_accuracy: 0.7755\n",
            "Epoch 58/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2945 - accuracy: 0.8860 - val_loss: 0.4817 - val_accuracy: 0.7755\n",
            "Epoch 59/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2930 - accuracy: 0.8860 - val_loss: 0.4812 - val_accuracy: 0.7755\n",
            "Epoch 60/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2915 - accuracy: 0.8860 - val_loss: 0.4806 - val_accuracy: 0.7755\n",
            "Epoch 61/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2903 - accuracy: 0.8860 - val_loss: 0.4800 - val_accuracy: 0.7755\n",
            "Epoch 62/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2889 - accuracy: 0.8912 - val_loss: 0.4793 - val_accuracy: 0.7755\n",
            "Epoch 63/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2876 - accuracy: 0.8912 - val_loss: 0.4786 - val_accuracy: 0.7755\n",
            "Epoch 64/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2864 - accuracy: 0.8912 - val_loss: 0.4782 - val_accuracy: 0.7755\n",
            "Epoch 65/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2850 - accuracy: 0.8912 - val_loss: 0.4784 - val_accuracy: 0.7755\n",
            "Epoch 66/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2842 - accuracy: 0.8912 - val_loss: 0.4789 - val_accuracy: 0.7755\n",
            "Epoch 67/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2843 - accuracy: 0.8860 - val_loss: 0.4791 - val_accuracy: 0.7755\n",
            "Epoch 68/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2852 - accuracy: 0.8912 - val_loss: 0.4795 - val_accuracy: 0.7347\n",
            "Epoch 69/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2859 - accuracy: 0.8756 - val_loss: 0.4797 - val_accuracy: 0.7755\n",
            "Epoch 70/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2859 - accuracy: 0.8705 - val_loss: 0.4793 - val_accuracy: 0.7755\n",
            "Epoch 71/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2851 - accuracy: 0.8705 - val_loss: 0.4779 - val_accuracy: 0.7347\n",
            "Epoch 72/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2829 - accuracy: 0.8756 - val_loss: 0.4767 - val_accuracy: 0.7755\n",
            "Epoch 73/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2797 - accuracy: 0.8860 - val_loss: 0.4764 - val_accuracy: 0.7755\n",
            "Epoch 74/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2778 - accuracy: 0.8912 - val_loss: 0.4790 - val_accuracy: 0.7755\n",
            "Epoch 75/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2767 - accuracy: 0.8860 - val_loss: 0.4806 - val_accuracy: 0.7755\n",
            "Epoch 76/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2757 - accuracy: 0.8912 - val_loss: 0.4810 - val_accuracy: 0.7755\n",
            "Epoch 77/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2749 - accuracy: 0.8912 - val_loss: 0.4810 - val_accuracy: 0.7755\n",
            "Epoch 78/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2742 - accuracy: 0.8912 - val_loss: 0.4811 - val_accuracy: 0.7755\n",
            "Epoch 79/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2738 - accuracy: 0.8912 - val_loss: 0.4800 - val_accuracy: 0.7755\n",
            "Epoch 80/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2726 - accuracy: 0.8912 - val_loss: 0.4792 - val_accuracy: 0.7755\n",
            "Epoch 81/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2718 - accuracy: 0.8912 - val_loss: 0.4790 - val_accuracy: 0.7755\n",
            "Epoch 82/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2713 - accuracy: 0.8912 - val_loss: 0.4787 - val_accuracy: 0.7755\n",
            "Epoch 83/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2699 - accuracy: 0.8912 - val_loss: 0.4772 - val_accuracy: 0.7755\n",
            "Epoch 84/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2688 - accuracy: 0.8964 - val_loss: 0.4765 - val_accuracy: 0.7755\n",
            "Epoch 85/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2678 - accuracy: 0.8964 - val_loss: 0.4760 - val_accuracy: 0.7755\n",
            "Epoch 86/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2669 - accuracy: 0.8964 - val_loss: 0.4757 - val_accuracy: 0.7755\n",
            "Epoch 87/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2660 - accuracy: 0.8964 - val_loss: 0.4755 - val_accuracy: 0.7755\n",
            "Epoch 88/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2652 - accuracy: 0.8964 - val_loss: 0.4752 - val_accuracy: 0.7755\n",
            "Epoch 89/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2642 - accuracy: 0.8964 - val_loss: 0.4749 - val_accuracy: 0.7755\n",
            "Epoch 90/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2635 - accuracy: 0.8964 - val_loss: 0.4747 - val_accuracy: 0.7755\n",
            "Epoch 91/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2629 - accuracy: 0.8964 - val_loss: 0.4745 - val_accuracy: 0.7755\n",
            "Epoch 92/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.2619 - accuracy: 0.8964 - val_loss: 0.4741 - val_accuracy: 0.7755\n",
            "Epoch 93/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2612 - accuracy: 0.8964 - val_loss: 0.4733 - val_accuracy: 0.7755\n",
            "Epoch 94/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2603 - accuracy: 0.8964 - val_loss: 0.4714 - val_accuracy: 0.7755\n",
            "Epoch 95/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.2598 - accuracy: 0.9016 - val_loss: 0.4705 - val_accuracy: 0.7755\n",
            "Epoch 96/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2594 - accuracy: 0.8964 - val_loss: 0.4699 - val_accuracy: 0.7755\n",
            "Epoch 97/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2585 - accuracy: 0.8964 - val_loss: 0.4697 - val_accuracy: 0.7755\n",
            "Epoch 98/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2579 - accuracy: 0.8964 - val_loss: 0.4701 - val_accuracy: 0.7755\n",
            "Epoch 99/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2571 - accuracy: 0.8964 - val_loss: 0.4717 - val_accuracy: 0.7755\n",
            "Epoch 100/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2564 - accuracy: 0.8964 - val_loss: 0.4728 - val_accuracy: 0.7755\n",
            "Epoch 101/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2556 - accuracy: 0.8964 - val_loss: 0.4731 - val_accuracy: 0.7755\n",
            "Epoch 102/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2547 - accuracy: 0.8964 - val_loss: 0.4728 - val_accuracy: 0.7755\n",
            "Epoch 103/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2546 - accuracy: 0.8964 - val_loss: 0.4712 - val_accuracy: 0.7755\n",
            "Epoch 104/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2536 - accuracy: 0.8964 - val_loss: 0.4703 - val_accuracy: 0.7755\n",
            "Epoch 105/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2533 - accuracy: 0.8964 - val_loss: 0.4696 - val_accuracy: 0.7755\n",
            "Epoch 106/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2527 - accuracy: 0.8964 - val_loss: 0.4687 - val_accuracy: 0.7755\n",
            "Epoch 107/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2521 - accuracy: 0.8964 - val_loss: 0.4678 - val_accuracy: 0.7755\n",
            "Epoch 108/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2516 - accuracy: 0.8964 - val_loss: 0.4674 - val_accuracy: 0.7755\n",
            "Epoch 109/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2509 - accuracy: 0.8964 - val_loss: 0.4670 - val_accuracy: 0.7755\n",
            "Epoch 110/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2498 - accuracy: 0.8964 - val_loss: 0.4671 - val_accuracy: 0.7755\n",
            "Epoch 111/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2486 - accuracy: 0.8964 - val_loss: 0.4683 - val_accuracy: 0.7755\n",
            "Epoch 112/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2477 - accuracy: 0.8964 - val_loss: 0.4692 - val_accuracy: 0.7755\n",
            "Epoch 113/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2469 - accuracy: 0.9016 - val_loss: 0.4702 - val_accuracy: 0.7755\n",
            "Epoch 114/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2464 - accuracy: 0.9016 - val_loss: 0.4720 - val_accuracy: 0.7755\n",
            "Epoch 115/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2456 - accuracy: 0.9016 - val_loss: 0.4716 - val_accuracy: 0.7755\n",
            "Epoch 116/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2454 - accuracy: 0.9016 - val_loss: 0.4672 - val_accuracy: 0.7755\n",
            "Epoch 117/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2445 - accuracy: 0.9016 - val_loss: 0.4654 - val_accuracy: 0.7755\n",
            "Epoch 118/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2439 - accuracy: 0.9067 - val_loss: 0.4642 - val_accuracy: 0.7755\n",
            "Epoch 119/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2429 - accuracy: 0.9067 - val_loss: 0.4630 - val_accuracy: 0.7551\n",
            "Epoch 120/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2431 - accuracy: 0.9119 - val_loss: 0.4623 - val_accuracy: 0.7551\n",
            "Epoch 121/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2422 - accuracy: 0.9067 - val_loss: 0.4621 - val_accuracy: 0.7755\n",
            "Epoch 122/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2407 - accuracy: 0.9016 - val_loss: 0.4622 - val_accuracy: 0.7755\n",
            "Epoch 123/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2400 - accuracy: 0.9016 - val_loss: 0.4626 - val_accuracy: 0.7755\n",
            "Epoch 124/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2392 - accuracy: 0.9016 - val_loss: 0.4633 - val_accuracy: 0.7755\n",
            "Epoch 125/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2386 - accuracy: 0.8964 - val_loss: 0.4633 - val_accuracy: 0.7755\n",
            "Epoch 126/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2375 - accuracy: 0.8964 - val_loss: 0.4634 - val_accuracy: 0.7755\n",
            "Epoch 127/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2367 - accuracy: 0.8964 - val_loss: 0.4624 - val_accuracy: 0.7755\n",
            "Epoch 128/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2360 - accuracy: 0.8964 - val_loss: 0.4618 - val_accuracy: 0.7755\n",
            "Epoch 129/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2352 - accuracy: 0.8964 - val_loss: 0.4619 - val_accuracy: 0.7755\n",
            "Epoch 130/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2342 - accuracy: 0.8964 - val_loss: 0.4614 - val_accuracy: 0.7755\n",
            "Epoch 131/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2339 - accuracy: 0.8964 - val_loss: 0.4609 - val_accuracy: 0.7755\n",
            "Epoch 132/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2336 - accuracy: 0.8964 - val_loss: 0.4601 - val_accuracy: 0.7755\n",
            "Epoch 133/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2326 - accuracy: 0.8964 - val_loss: 0.4603 - val_accuracy: 0.7755\n",
            "Epoch 134/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2320 - accuracy: 0.8964 - val_loss: 0.4616 - val_accuracy: 0.7755\n",
            "Epoch 135/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2307 - accuracy: 0.9016 - val_loss: 0.4643 - val_accuracy: 0.7551\n",
            "Epoch 136/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2306 - accuracy: 0.9016 - val_loss: 0.4662 - val_accuracy: 0.7551\n",
            "Epoch 137/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2316 - accuracy: 0.9067 - val_loss: 0.4637 - val_accuracy: 0.7551\n",
            "Epoch 138/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2302 - accuracy: 0.9119 - val_loss: 0.4578 - val_accuracy: 0.7551\n",
            "Epoch 139/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2287 - accuracy: 0.9119 - val_loss: 0.4552 - val_accuracy: 0.7551\n",
            "Epoch 140/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2279 - accuracy: 0.9119 - val_loss: 0.4536 - val_accuracy: 0.7551\n",
            "Epoch 141/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2273 - accuracy: 0.9067 - val_loss: 0.4530 - val_accuracy: 0.7551\n",
            "Epoch 142/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2266 - accuracy: 0.9067 - val_loss: 0.4534 - val_accuracy: 0.7551\n",
            "Epoch 143/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2259 - accuracy: 0.9067 - val_loss: 0.4559 - val_accuracy: 0.7551\n",
            "Epoch 144/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2250 - accuracy: 0.9067 - val_loss: 0.4608 - val_accuracy: 0.7551\n",
            "Epoch 145/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2238 - accuracy: 0.9119 - val_loss: 0.4632 - val_accuracy: 0.7551\n",
            "Epoch 146/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2233 - accuracy: 0.9119 - val_loss: 0.4649 - val_accuracy: 0.7551\n",
            "Epoch 147/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2227 - accuracy: 0.9119 - val_loss: 0.4661 - val_accuracy: 0.7551\n",
            "Epoch 148/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2220 - accuracy: 0.9119 - val_loss: 0.4666 - val_accuracy: 0.7551\n",
            "Epoch 149/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2213 - accuracy: 0.9119 - val_loss: 0.4667 - val_accuracy: 0.7551\n",
            "Epoch 150/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2207 - accuracy: 0.9119 - val_loss: 0.4665 - val_accuracy: 0.7551\n",
            "Epoch 151/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2200 - accuracy: 0.9119 - val_loss: 0.4665 - val_accuracy: 0.7551\n",
            "Epoch 152/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2194 - accuracy: 0.9119 - val_loss: 0.4667 - val_accuracy: 0.7551\n",
            "Epoch 153/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2187 - accuracy: 0.9119 - val_loss: 0.4669 - val_accuracy: 0.7551\n",
            "Epoch 154/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2181 - accuracy: 0.9119 - val_loss: 0.4671 - val_accuracy: 0.7551\n",
            "Epoch 155/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2176 - accuracy: 0.9119 - val_loss: 0.4665 - val_accuracy: 0.7551\n",
            "Epoch 156/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2173 - accuracy: 0.9119 - val_loss: 0.4629 - val_accuracy: 0.7551\n",
            "Epoch 157/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2158 - accuracy: 0.9171 - val_loss: 0.4611 - val_accuracy: 0.7551\n",
            "Epoch 158/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2161 - accuracy: 0.9171 - val_loss: 0.4605 - val_accuracy: 0.7551\n",
            "Epoch 159/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2157 - accuracy: 0.9171 - val_loss: 0.4603 - val_accuracy: 0.7551\n",
            "Epoch 160/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2152 - accuracy: 0.9171 - val_loss: 0.4603 - val_accuracy: 0.7551\n",
            "Epoch 161/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2150 - accuracy: 0.9171 - val_loss: 0.4591 - val_accuracy: 0.7551\n",
            "Epoch 162/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2152 - accuracy: 0.9171 - val_loss: 0.4593 - val_accuracy: 0.7551\n",
            "Epoch 163/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2145 - accuracy: 0.9171 - val_loss: 0.4597 - val_accuracy: 0.7755\n",
            "Epoch 164/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2140 - accuracy: 0.9171 - val_loss: 0.4602 - val_accuracy: 0.7959\n",
            "Epoch 165/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2136 - accuracy: 0.9171 - val_loss: 0.4606 - val_accuracy: 0.7959\n",
            "Epoch 166/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2129 - accuracy: 0.9171 - val_loss: 0.4611 - val_accuracy: 0.7959\n",
            "Epoch 167/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2122 - accuracy: 0.9171 - val_loss: 0.4614 - val_accuracy: 0.7755\n",
            "Epoch 168/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.2115 - accuracy: 0.9171 - val_loss: 0.4605 - val_accuracy: 0.7959\n",
            "Epoch 169/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2110 - accuracy: 0.9171 - val_loss: 0.4574 - val_accuracy: 0.7959\n",
            "Epoch 170/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2118 - accuracy: 0.9171 - val_loss: 0.4564 - val_accuracy: 0.7959\n",
            "Epoch 171/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2110 - accuracy: 0.9171 - val_loss: 0.4567 - val_accuracy: 0.7959\n",
            "Epoch 172/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2093 - accuracy: 0.9223 - val_loss: 0.4566 - val_accuracy: 0.7959\n",
            "Epoch 173/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2086 - accuracy: 0.9223 - val_loss: 0.4572 - val_accuracy: 0.7755\n",
            "Epoch 174/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2076 - accuracy: 0.9275 - val_loss: 0.4581 - val_accuracy: 0.7551\n",
            "Epoch 175/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2061 - accuracy: 0.9223 - val_loss: 0.4583 - val_accuracy: 0.7755\n",
            "Epoch 176/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2056 - accuracy: 0.9223 - val_loss: 0.4574 - val_accuracy: 0.7755\n",
            "Epoch 177/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2047 - accuracy: 0.9223 - val_loss: 0.4579 - val_accuracy: 0.7959\n",
            "Epoch 178/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2043 - accuracy: 0.9275 - val_loss: 0.4587 - val_accuracy: 0.7755\n",
            "Epoch 179/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2042 - accuracy: 0.9275 - val_loss: 0.4605 - val_accuracy: 0.7755\n",
            "Epoch 180/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2033 - accuracy: 0.9275 - val_loss: 0.4602 - val_accuracy: 0.7755\n",
            "Epoch 181/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2026 - accuracy: 0.9223 - val_loss: 0.4598 - val_accuracy: 0.7959\n",
            "Epoch 182/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2017 - accuracy: 0.9223 - val_loss: 0.4579 - val_accuracy: 0.7959\n",
            "Epoch 183/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2021 - accuracy: 0.9275 - val_loss: 0.4569 - val_accuracy: 0.7959\n",
            "Epoch 184/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2016 - accuracy: 0.9275 - val_loss: 0.4575 - val_accuracy: 0.8163\n",
            "Epoch 185/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2011 - accuracy: 0.9275 - val_loss: 0.4588 - val_accuracy: 0.8163\n",
            "Epoch 186/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2001 - accuracy: 0.9275 - val_loss: 0.4594 - val_accuracy: 0.8163\n",
            "Epoch 187/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1991 - accuracy: 0.9223 - val_loss: 0.4606 - val_accuracy: 0.7959\n",
            "Epoch 188/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1985 - accuracy: 0.9223 - val_loss: 0.4612 - val_accuracy: 0.7959\n",
            "Epoch 189/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1981 - accuracy: 0.9223 - val_loss: 0.4605 - val_accuracy: 0.7959\n",
            "Epoch 190/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1972 - accuracy: 0.9223 - val_loss: 0.4587 - val_accuracy: 0.7959\n",
            "Epoch 191/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1972 - accuracy: 0.9275 - val_loss: 0.4583 - val_accuracy: 0.8163\n",
            "Epoch 192/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1965 - accuracy: 0.9275 - val_loss: 0.4572 - val_accuracy: 0.7959\n",
            "Epoch 193/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1963 - accuracy: 0.9275 - val_loss: 0.4521 - val_accuracy: 0.8163\n",
            "Epoch 194/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1961 - accuracy: 0.9171 - val_loss: 0.4509 - val_accuracy: 0.8163\n",
            "Epoch 195/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1962 - accuracy: 0.9119 - val_loss: 0.4512 - val_accuracy: 0.7959\n",
            "Epoch 196/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1959 - accuracy: 0.9119 - val_loss: 0.4531 - val_accuracy: 0.7959\n",
            "Epoch 197/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1957 - accuracy: 0.9119 - val_loss: 0.4541 - val_accuracy: 0.7959\n",
            "Epoch 198/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1950 - accuracy: 0.9119 - val_loss: 0.4554 - val_accuracy: 0.7959\n",
            "Epoch 199/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1944 - accuracy: 0.9119 - val_loss: 0.4567 - val_accuracy: 0.8163\n",
            "Epoch 200/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1935 - accuracy: 0.9119 - val_loss: 0.4570 - val_accuracy: 0.8163\n",
            "Epoch 201/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1928 - accuracy: 0.9171 - val_loss: 0.4571 - val_accuracy: 0.8163\n",
            "Epoch 202/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1923 - accuracy: 0.9171 - val_loss: 0.4589 - val_accuracy: 0.7959\n",
            "Epoch 203/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1919 - accuracy: 0.9223 - val_loss: 0.4597 - val_accuracy: 0.7959\n",
            "Epoch 204/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1918 - accuracy: 0.9171 - val_loss: 0.4598 - val_accuracy: 0.8163\n",
            "Epoch 205/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1908 - accuracy: 0.9171 - val_loss: 0.4609 - val_accuracy: 0.7959\n",
            "Epoch 206/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1916 - accuracy: 0.9275 - val_loss: 0.4652 - val_accuracy: 0.7959\n",
            "Epoch 207/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1900 - accuracy: 0.9223 - val_loss: 0.4698 - val_accuracy: 0.7959\n",
            "Epoch 208/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1900 - accuracy: 0.9223 - val_loss: 0.4711 - val_accuracy: 0.7959\n",
            "Epoch 209/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1891 - accuracy: 0.9223 - val_loss: 0.4708 - val_accuracy: 0.7959\n",
            "Epoch 210/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1881 - accuracy: 0.9223 - val_loss: 0.4679 - val_accuracy: 0.7959\n",
            "Epoch 211/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1881 - accuracy: 0.9223 - val_loss: 0.4667 - val_accuracy: 0.7959\n",
            "Epoch 212/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1877 - accuracy: 0.9275 - val_loss: 0.4661 - val_accuracy: 0.7959\n",
            "Epoch 213/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1874 - accuracy: 0.9275 - val_loss: 0.4673 - val_accuracy: 0.7959\n",
            "Epoch 214/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1872 - accuracy: 0.9223 - val_loss: 0.4675 - val_accuracy: 0.7959\n",
            "Epoch 215/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1864 - accuracy: 0.9275 - val_loss: 0.4676 - val_accuracy: 0.7959\n",
            "Epoch 216/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1856 - accuracy: 0.9326 - val_loss: 0.4687 - val_accuracy: 0.7959\n",
            "Epoch 217/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1852 - accuracy: 0.9326 - val_loss: 0.4696 - val_accuracy: 0.7959\n",
            "Epoch 218/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1844 - accuracy: 0.9326 - val_loss: 0.4692 - val_accuracy: 0.7959\n",
            "Epoch 219/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1835 - accuracy: 0.9326 - val_loss: 0.4688 - val_accuracy: 0.8163\n",
            "Epoch 220/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1829 - accuracy: 0.9275 - val_loss: 0.4686 - val_accuracy: 0.8163\n",
            "Epoch 221/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1823 - accuracy: 0.9223 - val_loss: 0.4688 - val_accuracy: 0.8163\n",
            "Epoch 222/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1818 - accuracy: 0.9223 - val_loss: 0.4689 - val_accuracy: 0.8163\n",
            "Epoch 223/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1814 - accuracy: 0.9223 - val_loss: 0.4689 - val_accuracy: 0.8163\n",
            "Epoch 224/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1808 - accuracy: 0.9223 - val_loss: 0.4691 - val_accuracy: 0.8163\n",
            "Epoch 225/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1804 - accuracy: 0.9223 - val_loss: 0.4684 - val_accuracy: 0.8163\n",
            "Epoch 226/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1800 - accuracy: 0.9223 - val_loss: 0.4666 - val_accuracy: 0.7959\n",
            "Epoch 227/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1798 - accuracy: 0.9275 - val_loss: 0.4608 - val_accuracy: 0.8163\n",
            "Epoch 228/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1811 - accuracy: 0.9326 - val_loss: 0.4576 - val_accuracy: 0.8163\n",
            "Epoch 229/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1815 - accuracy: 0.9326 - val_loss: 0.4568 - val_accuracy: 0.8163\n",
            "Epoch 230/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1814 - accuracy: 0.9326 - val_loss: 0.4580 - val_accuracy: 0.8163\n",
            "Epoch 231/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1807 - accuracy: 0.9326 - val_loss: 0.4588 - val_accuracy: 0.8163\n",
            "Epoch 232/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1798 - accuracy: 0.9326 - val_loss: 0.4603 - val_accuracy: 0.8163\n",
            "Epoch 233/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1794 - accuracy: 0.9326 - val_loss: 0.4652 - val_accuracy: 0.8163\n",
            "Epoch 234/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1794 - accuracy: 0.9378 - val_loss: 0.4668 - val_accuracy: 0.8163\n",
            "Epoch 235/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1791 - accuracy: 0.9378 - val_loss: 0.4676 - val_accuracy: 0.8163\n",
            "Epoch 236/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1782 - accuracy: 0.9378 - val_loss: 0.4680 - val_accuracy: 0.8163\n",
            "Epoch 237/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1775 - accuracy: 0.9378 - val_loss: 0.4685 - val_accuracy: 0.8163\n",
            "Epoch 238/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1768 - accuracy: 0.9378 - val_loss: 0.4691 - val_accuracy: 0.8163\n",
            "Epoch 239/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1763 - accuracy: 0.9378 - val_loss: 0.4695 - val_accuracy: 0.8163\n",
            "Epoch 240/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1753 - accuracy: 0.9378 - val_loss: 0.4701 - val_accuracy: 0.8163\n",
            "Epoch 241/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1746 - accuracy: 0.9378 - val_loss: 0.4704 - val_accuracy: 0.8163\n",
            "Epoch 242/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1741 - accuracy: 0.9378 - val_loss: 0.4702 - val_accuracy: 0.8163\n",
            "Epoch 243/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1738 - accuracy: 0.9378 - val_loss: 0.4710 - val_accuracy: 0.8163\n",
            "Epoch 244/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1731 - accuracy: 0.9326 - val_loss: 0.4709 - val_accuracy: 0.8163\n",
            "Epoch 245/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1724 - accuracy: 0.9326 - val_loss: 0.4708 - val_accuracy: 0.8163\n",
            "Epoch 246/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1718 - accuracy: 0.9326 - val_loss: 0.4710 - val_accuracy: 0.8163\n",
            "Epoch 247/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1712 - accuracy: 0.9326 - val_loss: 0.4705 - val_accuracy: 0.8163\n",
            "Epoch 248/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1714 - accuracy: 0.9378 - val_loss: 0.4693 - val_accuracy: 0.8163\n",
            "Epoch 249/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1715 - accuracy: 0.9378 - val_loss: 0.4706 - val_accuracy: 0.8163\n",
            "Epoch 250/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1712 - accuracy: 0.9326 - val_loss: 0.4725 - val_accuracy: 0.8163\n",
            "Epoch 251/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1695 - accuracy: 0.9326 - val_loss: 0.4734 - val_accuracy: 0.8163\n",
            "Epoch 252/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1690 - accuracy: 0.9326 - val_loss: 0.4741 - val_accuracy: 0.8163\n",
            "Epoch 253/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1685 - accuracy: 0.9326 - val_loss: 0.4753 - val_accuracy: 0.7959\n",
            "Epoch 254/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1679 - accuracy: 0.9326 - val_loss: 0.4758 - val_accuracy: 0.7959\n",
            "Epoch 255/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1675 - accuracy: 0.9326 - val_loss: 0.4761 - val_accuracy: 0.7959\n",
            "Epoch 256/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1670 - accuracy: 0.9326 - val_loss: 0.4761 - val_accuracy: 0.7959\n",
            "Epoch 257/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1665 - accuracy: 0.9326 - val_loss: 0.4762 - val_accuracy: 0.7959\n",
            "Epoch 258/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1661 - accuracy: 0.9326 - val_loss: 0.4779 - val_accuracy: 0.7959\n",
            "Epoch 259/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1660 - accuracy: 0.9326 - val_loss: 0.4788 - val_accuracy: 0.7959\n",
            "Epoch 260/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1657 - accuracy: 0.9275 - val_loss: 0.4785 - val_accuracy: 0.7959\n",
            "Epoch 261/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1652 - accuracy: 0.9326 - val_loss: 0.4786 - val_accuracy: 0.7959\n",
            "Epoch 262/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1645 - accuracy: 0.9275 - val_loss: 0.4787 - val_accuracy: 0.7959\n",
            "Epoch 263/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1638 - accuracy: 0.9326 - val_loss: 0.4793 - val_accuracy: 0.7959\n",
            "Epoch 264/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1633 - accuracy: 0.9326 - val_loss: 0.4786 - val_accuracy: 0.7959\n",
            "Epoch 265/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1627 - accuracy: 0.9378 - val_loss: 0.4745 - val_accuracy: 0.8163\n",
            "Epoch 266/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1647 - accuracy: 0.9326 - val_loss: 0.4734 - val_accuracy: 0.8163\n",
            "Epoch 267/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1643 - accuracy: 0.9378 - val_loss: 0.4718 - val_accuracy: 0.8163\n",
            "Epoch 268/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1644 - accuracy: 0.9326 - val_loss: 0.4693 - val_accuracy: 0.8163\n",
            "Epoch 269/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1645 - accuracy: 0.9326 - val_loss: 0.4676 - val_accuracy: 0.8163\n",
            "Epoch 270/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1635 - accuracy: 0.9378 - val_loss: 0.4663 - val_accuracy: 0.8163\n",
            "Epoch 271/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1634 - accuracy: 0.9378 - val_loss: 0.4659 - val_accuracy: 0.8163\n",
            "Epoch 272/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1638 - accuracy: 0.9326 - val_loss: 0.4655 - val_accuracy: 0.8163\n",
            "Epoch 273/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1631 - accuracy: 0.9378 - val_loss: 0.4651 - val_accuracy: 0.8163\n",
            "Epoch 274/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1624 - accuracy: 0.9326 - val_loss: 0.4683 - val_accuracy: 0.8163\n",
            "Epoch 275/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1620 - accuracy: 0.9326 - val_loss: 0.4696 - val_accuracy: 0.8163\n",
            "Epoch 276/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1617 - accuracy: 0.9378 - val_loss: 0.4714 - val_accuracy: 0.7959\n",
            "Epoch 277/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1612 - accuracy: 0.9378 - val_loss: 0.4717 - val_accuracy: 0.7959\n",
            "Epoch 278/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1605 - accuracy: 0.9378 - val_loss: 0.4735 - val_accuracy: 0.7959\n",
            "Epoch 279/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1601 - accuracy: 0.9378 - val_loss: 0.4736 - val_accuracy: 0.8163\n",
            "Epoch 280/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1592 - accuracy: 0.9378 - val_loss: 0.4718 - val_accuracy: 0.8163\n",
            "Epoch 281/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1580 - accuracy: 0.9430 - val_loss: 0.4689 - val_accuracy: 0.8163\n",
            "Epoch 282/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1573 - accuracy: 0.9430 - val_loss: 0.4683 - val_accuracy: 0.8163\n",
            "Epoch 283/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1567 - accuracy: 0.9430 - val_loss: 0.4686 - val_accuracy: 0.8163\n",
            "Epoch 284/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1559 - accuracy: 0.9430 - val_loss: 0.4700 - val_accuracy: 0.8163\n",
            "Epoch 285/300\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1553 - accuracy: 0.9430 - val_loss: 0.4718 - val_accuracy: 0.8163\n",
            "Epoch 286/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1558 - accuracy: 0.9378 - val_loss: 0.4747 - val_accuracy: 0.8163\n",
            "Epoch 287/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1553 - accuracy: 0.9378 - val_loss: 0.4759 - val_accuracy: 0.8163\n",
            "Epoch 288/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1562 - accuracy: 0.9430 - val_loss: 0.4754 - val_accuracy: 0.7959\n",
            "Epoch 289/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1573 - accuracy: 0.9378 - val_loss: 0.4740 - val_accuracy: 0.7959\n",
            "Epoch 290/300\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1573 - accuracy: 0.9378 - val_loss: 0.4729 - val_accuracy: 0.8163\n",
            "Epoch 291/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1562 - accuracy: 0.9378 - val_loss: 0.4716 - val_accuracy: 0.8163\n",
            "Epoch 292/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1552 - accuracy: 0.9378 - val_loss: 0.4717 - val_accuracy: 0.8163\n",
            "Epoch 293/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1548 - accuracy: 0.9378 - val_loss: 0.4718 - val_accuracy: 0.8163\n",
            "Epoch 294/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1540 - accuracy: 0.9378 - val_loss: 0.4744 - val_accuracy: 0.8163\n",
            "Epoch 295/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1538 - accuracy: 0.9378 - val_loss: 0.4771 - val_accuracy: 0.8163\n",
            "Epoch 296/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1533 - accuracy: 0.9378 - val_loss: 0.4783 - val_accuracy: 0.8163\n",
            "Epoch 297/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1527 - accuracy: 0.9378 - val_loss: 0.4787 - val_accuracy: 0.8163\n",
            "Epoch 298/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1520 - accuracy: 0.9430 - val_loss: 0.4790 - val_accuracy: 0.8163\n",
            "Epoch 299/300\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1514 - accuracy: 0.9378 - val_loss: 0.4790 - val_accuracy: 0.8163\n",
            "Epoch 300/300\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1504 - accuracy: 0.9378 - val_loss: 0.4798 - val_accuracy: 0.8163\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_X,\n",
        "                    train_y,\n",
        "                    epochs=300,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the training and loss curves to see if ***overfitting*** is going on and if **early stopping** may be needed."
      ],
      "metadata": {
        "id": "fcSh9odtRzSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p507juxRR29_",
        "outputId": "7b8750a4-f75c-4e0f-bf85-521555c18a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "n4WU9GeVR6QW",
        "outputId": "9b94a3ea-1b40-49da-ad3c-c04b5f93f77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you think there's overfitting?\n",
        "\n",
        "If you think there's overfitting at epoch N, we could go back, re-initialize the model and just run it for  N epochs - that would an example of **early stopping**.\n",
        "\n",
        "Let's look at the accuracy curves as well.\n",
        "\n"
      ],
      "metadata": {
        "id": "nqh87CoqVuNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.clf()\n",
        "acc = history_dict[\"accuracy\"]\n",
        "val_acc = history_dict[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "z-tzis2kSlw1",
        "outputId": "2631f979-f95d-4ce9-944f-338df0f385fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model\n",
        "\n",
        "Let's see **how well the model does on the test set**. \n",
        "\n",
        "`model.evaluate` is a very handy function to calculate the performance of your model on any dataset."
      ],
      "metadata": {
        "id": "uWI1kI27RZun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_X, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDyP_S4LRlb9",
        "outputId": "5374f620-b557-44ec-9e12-ec5d5c07d7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8033\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36425456404685974, 0.8032786846160889]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4GzDJ1I8pgw"
      },
      "source": [
        "## Predicting new data (i.e., *inference*) with the model\n",
        "\n",
        "We will see in later colabs how to save a Keras model and use it for prediction later.  But we want to point out that the simple approach we followed in this colab has a key shortcoming.\n",
        "\n",
        "We did the pre-processing - the one-hot encoding and normalization - *outside* the model. This means that we have to remember what pre-processing we did and carry that information (e.g., the mean and variance of each variable) along with the model to correctly use the model in the future.\n",
        "\n",
        "A very elegant way to avoid this issue is to use [Keras preprocessing layers](https://keras.io/guides/preprocessing_layers/). In the interest of time, we aren't covering it in this colab but we encourage you to check out this [colab](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/structured_data/ipynb/structured_data_classification_from_scratch.ipynb) which shows how to solve our exact heart-disease prediction problem above using preprocessing layers.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HODL-Lecture 2-Heart-Disease-Prediction",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}